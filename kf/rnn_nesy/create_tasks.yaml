name: Create Continual Learning Tasks
description: Splits data into multiple tasks for continual learning.
inputs:
  - {name: train_loader, type: Dataset}
  - {name: test_loader, type: Dataset}
  - {name: config, type: String}
outputs:
  - {name: tasks, type: Dataset}
implementation:
  container:
    image: kushagra4761/nesy-factory-library
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import pickle
        import numpy as np
        import torch
        from torch.utils.data import TensorDataset, DataLoader

        class TemporalDataSplitter:
          
          def __init__(self, data, config, strategy='temporal_split'):
              self.data = data
              self.config = config
              self.strategy = strategy
              
          def create_continual_tasks(self, num_tasks: int = 3) -> list:
              return self._temporal_split(num_tasks)
          
          def _temporal_split(self, num_tasks: int) -> list:
              tasks = []
              
              X_train = self.data['X_train']
              y_train = self.data['y_train']
              X_test = self.data['X_test']
              y_test = self.data['y_test']

              train_size = len(X_train)
              test_size = len(X_test)
              
              train_splits = np.array_split(range(train_size), num_tasks)
              test_splits = np.array_split(range(test_size), num_tasks)
              
              for i in range(num_tasks):
                  task_data = {
                      'task_id': i,
                      'X_train': X_train[train_splits[i]],
                      'y_train': y_train[train_splits[i]],
                      'X_test': X_test[test_splits[i]],
                      'y_test': y_test[test_splits[i]],
                      'description': f'Temporal Period {i+1}/{num_tasks}'
                  }
                  
                  train_dataset = TensorDataset(torch.tensor(task_data['X_train'], dtype=torch.float32), torch.tensor(task_data['y_train'], dtype=torch.float32).unsqueeze(1))
                  test_dataset = TensorDataset(torch.tensor(task_data['X_test'], dtype=torch.float32), torch.tensor(task_data['y_test'], dtype=torch.float32).unsqueeze(1))

                  task_data['train_loader'] = DataLoader(train_dataset, batch_size=self.config.get('batch_size', 32), shuffle=True)
                  task_data['test_loader'] = DataLoader(test_dataset, batch_size=self.config.get('batch_size', 32), shuffle=False)
                  
                  tasks.append(task_data)
              
              return tasks

        def main():
            parser = argparse.ArgumentParser()
            parser.add_argument('--train_loader', type=str, required=True)
            parser.add_argument('--test_loader', type=str, required=True)
            parser.add_argument('--config', type=str, required=True)
            parser.add_argument('--tasks', type=str, required=True)
            args = parser.parse_args()

            config = json.loads(args.config)

            with open(args.train_loader, 'rb') as f:
                train_loader = pickle.load(f)
            
            with open(args.test_loader, 'rb') as f:
                test_loader = pickle.load(f)

            X_train = train_loader.dataset.tensors[0].numpy()
            y_train = train_loader.dataset.tensors[1].numpy().squeeze()
            X_test = test_loader.dataset.tensors[0].numpy()
            y_test = test_loader.dataset.tensors[1].numpy().squeeze()

            data = {
                'X_train': X_train,
                'y_train': y_train,
                'X_test': X_test,
                'y_test': y_test
            }
            
            splitter = TemporalDataSplitter(data, config, strategy=config.get('cl_strategy', 'temporal_split'))
            tasks = splitter.create_continual_tasks(num_tasks=config.get('num_tasks', 3))

            os.makedirs(os.path.dirname(args.tasks), exist_ok=True)
            with open(args.tasks, "wb") as f:
                pickle.dump(tasks, f)

            print(f"Saved tasks to {args.tasks}")

        if __name__ == '__main__':
            main()
    args:
      - --train_loader
      - {inputPath: train_loader}
      - --test_loader
      - {inputPath: test_loader}
      - --config
      - {inputValue: config}
      - --tasks
      - {outputPath: tasks}